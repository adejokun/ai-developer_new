{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Watson OpenScale Mortgage Default Demo"}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook should be run in a [Watson Studio](https://dataplatform.ibm.com/) project with Python 3.6 or greater. It requires a free lite version of [Watson Machine Learning](https://cloud.ibm.com/catalog/services/machine-learning).\n\nThis notebook will train, save and deploy a machine learning model to predict mortgage defaults."}, {"metadata": {}, "cell_type": "markdown", "source": "## Provision services and create credentials"}, {"metadata": {}, "cell_type": "markdown", "source": "You will need credentials for Watson Machine Learning. If you already have a WML instance, you may use credentials for it. To provision a new Lite instance of WML, use the [Cloud catalog](https://cloud.ibm.com/catalog/services/machine-learning), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your WML credentials into the cell below."}, {"metadata": {}, "cell_type": "code", "source": "WML_CREDENTIALS = {\n    \"apikey\": \"key\",\n    \"iam_apikey_description\": \"description\",\n    \"iam_apikey_name\": \"auto-generated-apikey\",\n    \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n    \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::\",\n    \"instance_id\": \"instance_id\",\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "You can generate a Cloud API key [here](https://cloud.ibm.com/iam/apikeys)."}, {"metadata": {}, "cell_type": "code", "source": "CLOUD_API_KEY = \"xxxxxxxxxxxxxxxxx\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "CLOUD_API_KEY = \"C3zgbvO29qbcagfMFG70cr-hQrD6EbENzSgz3Cmpxw18\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "If you have already set up an OpenScale datamart, or if you would like to use the free internal PostgreSQL datamart, you can skip the following cell. If you are setting up a new instance of OpenScale and would like to use a paid database service, paste your Db2 or PostgreSQL credentials below."}, {"metadata": {}, "cell_type": "code", "source": "DB_CREDENTIALS = None", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Name your model"}, {"metadata": {}, "cell_type": "markdown", "source": "You may give your model and deployment a custom name below; however, if you change the values below, be sure to use the same names in all subsequent notebooks in this lab."}, {"metadata": {}, "cell_type": "code", "source": "MODEL_NAME = 'Mortgage Default'\nDEPLOYMENT_NAME = 'Mortgage Default - Production'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Run the notebook"}, {"metadata": {}, "cell_type": "markdown", "source": "At this point, you can run all cells in this notebook using the menus above."}, {"metadata": {}, "cell_type": "markdown", "source": "Import the scikit-learn framework and check the version. This notebook was developed using sklearn version 0.20.3."}, {"metadata": {}, "cell_type": "code", "source": "import sklearn\nsklearn.__version__", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Use the provided credentials above to create a new Watson Machine Learning client."}, {"metadata": {}, "cell_type": "code", "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n\nwml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "List all models for this instance of Watson Machine Learning."}, {"metadata": {}, "cell_type": "code", "source": "wml_client.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Import the pandas library, download and examine our training data. The data contains an 'ID' field for the loan ID, which will not be used in training the model and is dropped."}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\n\nurl = 'https://raw.githubusercontent.com/ericmartens/openscale_app/master/data/Mortgage_Full_Records.csv'\ndf_raw = pd.read_csv(url)\ndf = df_raw.drop('ID', axis=1)\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Import the sklearn libraries we need, including encoders, transformers, scalers, and our random forest classifier."}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Identify the categorical features, and create a one-hot encoder pipeline for them.\n\nNext, identify the numerical features and use the min-max scaler to scale the values, which will significantly increase our model's accuracy.\n\nFinally, organize the categorical encoder and the scaler into a pipeline so the deployed model can work with our data."}, {"metadata": {}, "cell_type": "code", "source": "categorical_features = ['AppliedOnline','Residence','Location']\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\nscaled_features = ['Income','Yrs_at_Current_Address','Yrs_with_Current_Employer',\\\n                   'Number_of_Cards','Creditcard_Debt','Loan_Amount','SalePrice']\nscale_transformer = Pipeline(steps=[('scale', MinMaxScaler())])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, categorical_features),\n        ('scaler', scale_transformer, scaled_features)\n    ]\n)\n\nclf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', RandomForestClassifier())])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Perform the train/test split, train the model, and score the model quality."}, {"metadata": {}, "cell_type": "code", "source": "X = df.drop('MortgageDefault', axis=1)\ny = df['MortgageDefault']\n\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n\nmodel = clf.fit(X_train, y_train)\nres_predict = model.predict(X_test)\nprint(\"model score: %.3f\" % clf.score(X_test, y_test))\nprint(classification_report(y_test, res_predict, target_names=[\"False\", \"True\"]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Save the model to Watson Machine Learning"}, {"metadata": {}, "cell_type": "markdown", "source": "Check the list of models in the WML instance, and remove pre-existing versions of this model. This allows the notebook to be re-run to reset all data if necessary."}, {"metadata": {}, "cell_type": "code", "source": "model_deployment_ids = wml_client.deployments.get_uids()\nfor deployment_id in model_deployment_ids:\n    deployment = wml_client.deployments.get_details(deployment_id)\n    model_id = deployment['entity']['deployable_asset']['guid']\n    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n        print('Deleting deployment id', deployment_id)\n        wml_client.deployments.delete(deployment_id)\n        print('Deleting model id', model_id)\n        wml_client.repository.delete(model_id)\nwml_client.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Create the metadata and save the model."}, {"metadata": {}, "cell_type": "code", "source": "metadata = {\n    wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n        {\n            \"name\": \"areaUnderROC\",\n            \"value\": 0.7,\n            \"threshold\": 0.7\n        }\n    ]\n}\n\n# Name the columns\ncols=[\"Income\",\"AppliedOnline\",\"Residence\",\"Yrs_at_Current_Address\",\"Yrs_with_Current_Employer\",\\\n      \"Number_of_Cards\",\"Creditcard_Debt\",\"Loans\",\"Loan_Amount\",\"SalePrice\",\"Location\"]\n      \nsaved_model = wml_client.repository.store_model(model=model, meta_props=metadata, \n                                            training_data=X_train, training_target=y_train, \n                                            feature_names=cols, label_column_names=[\"MortgageDefault\"] )\nsaved_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get the unique ID for the model so we can deploy it."}, {"metadata": {}, "cell_type": "code", "source": "model_uid = saved_model['metadata']['guid']\nmodel_uid", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Deploy the model as a web service with Watson Machine Learning."}, {"metadata": {}, "cell_type": "code", "source": "print(\"Deploying model...\")\n\ndeployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "deployment_uid = wml_client.deployments.get_uid(deployment)\n\nprint(\"Model id: {}\".format(model_uid))\nprint(\"Deployment id: {}\".format(deployment_uid))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# OpenScale Mortgage Default Configuration\n\nThis portion of the notebook will configure OpenScale to monitoring for the mortgage default model using the Python client, as opposed to the graphical user interface."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_ai_openscale import APIClient\nfrom ibm_ai_openscale.engines import *\nfrom ibm_ai_openscale.utils import *\nfrom ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\nfrom ibm_ai_openscale.supporting_classes.enums import *", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get the instance ID for Watson OpenScale."}, {"metadata": {}, "cell_type": "code", "source": "import requests\nfrom ibm_ai_openscale.utils import get_instance_guid\n\nWOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\nWOS_CREDENTIALS = {\n    \"instance_guid\": WOS_GUID,\n    \"apikey\": CLOUD_API_KEY,\n    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n}\n\nif WOS_GUID is None:\n    print('Watson OpenScale GUID NOT FOUND')\nelse:\n    print(WOS_GUID)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Use the Cloud API key and WOS instance ID to create a new OpenScale client."}, {"metadata": {}, "cell_type": "code", "source": "ai_client = APIClient(aios_credentials=WOS_CREDENTIALS)\nai_client.version", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Set up the OpenScale datamart. First check for an existing datamart. If none is found, create one using the DB_CREDENTIALS if provided. If no credentials were provided, use the free internal datamart."}, {"metadata": {}, "cell_type": "code", "source": "try:\n    data_mart_details = ai_client.data_mart.get_details()\n    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n        print('Using existing internal datamart')\n    else:\n        print('Using existing external datamart')\nexcept:\n    if DB_CREDENTIALS is None:\n        print('Setting up internal datamart')\n        ai_client.data_mart.setup(internal_db=True)\n    else:\n        print('Setting up external datamart')\n        try:\n            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n        except:\n            print('Setup failed, trying Db2 setup')\n            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS, schema=DB_CREDENTIALS['username'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data_mart_details = ai_client.data_mart.get_details()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Bind the OpenScale datamart to the WML instance. If the binding already exists, this will generate an error message, but will not affect the remainder of the notebook."}, {"metadata": {}, "cell_type": "code", "source": "binding_uid = ai_client.data_mart.bindings.add('WML Binding', WatsonMachineLearningInstance(WML_CREDENTIALS))\nbindings_details = ai_client.data_mart.bindings.get_details()\n\nai_client.data_mart.bindings.list()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(binding_uid)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Get the scoring endpoint for the deployed model."}, {"metadata": {}, "cell_type": "code", "source": "deployment_details = wml_client.deployments.get_details(deployment_uid)\nscoring_endpoint = deployment_details['entity']['scoring_url']\n\nprint('Model UID:', model_uid)\nprint('Scoring URL:', scoring_endpoint)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "List all the subscribed models."}, {"metadata": {}, "cell_type": "code", "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nai_client.data_mart.subscriptions.list()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The credentials below point to the training data for the model, in CSV format. OpenScale uses the training data to train the drift model, and generate distribution statistics for the explainability service and the fairness monitor. If you don't want to provide this information to OpenScale, it is possible to run a custom notebook to create this data."}, {"metadata": {}, "cell_type": "code", "source": "cos_credentials = {\n    \"apikey\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n    \"api_key\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n    \"url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\",\n    \"iam_url\": 'https://iam.bluemix.net/oidc/token',\n    \"cos_hmac_keys\": {\n        \"access_key_id\": \"2d1be760f19241d695a534960da6eb80\",\n        \"secret_access_key\": \"e1252b952f47a6b3f42305b8ffe6f9bd7d10e45f966b9a62\"\n    },\n    \"endpoints\": \"https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\",\n    \"iam_apikey_description\": \"Auto-generated for key 2d1be760-f192-41d6-95a5-34960da6eb80\",\n    \"iam_apikey_name\": \"FastStartLab\",\n    \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Reader\",\n    \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/7d8b3c34272c0980d973d3e40be9e9d2::serviceid:ServiceId-568ba191-a3bf-48f2-a30c-f3a4af7ec61d\",\n    \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/7d8b3c34272c0980d973d3e40be9e9d2:2883ef10-23f1-4592-8582-2f2ef4973639::\"\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "training_data_reference = {\n    'type': 'cos',\n    'location': {\n        'bucket': 'faststartlab-donotdelete-pr-nhfd4jnhlxgpc7',\n        'file_name': 'Mortgage_Full_Records.csv',\n        'firstlineheader': True,\n        'file_format': 'csv'\n    },\n    'connection': cos_credentials,\n    'name': 'training data reference'\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Remove previous subscriptions for this model"}, {"metadata": {}, "cell_type": "code", "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nfor subscription in subscriptions_uids:\n    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n    if sub_name == MODEL_NAME:\n        ai_client.data_mart.subscriptions.delete(subscription)\n        print('Deleted existing subscription for', MODEL_NAME)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Create the subscription in OpenScale so we can monitor the model. Required information includes feature columns, categorical columns, problem types, input types, and output types."}, {"metadata": {}, "cell_type": "code", "source": "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n    model_uid,\n    problem_type=ProblemType.BINARY_CLASSIFICATION,\n    input_data_type=InputDataType.STRUCTURED,\n    label_column='MortgageDefault',\n    prediction_column='prediction',\n    probability_column='probability',\n    transaction_id_column='ID',\n    feature_columns = ['AppliedOnline','Residence','Location','Income','Yrs_at_Current_Address','Yrs_with_Current_Employer',\\\n                   'Number_of_Cards','Creditcard_Debt','Loan_Amount','Loans','SalePrice'],\n    categorical_columns = ['AppliedOnline','Residence','Location'],\n    training_data_reference = training_data_reference\n))\n\nif subscription is None:\n    print('Subscription already exists; get the existing one')\n    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n    for sub in subscriptions_uids:\n        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n            subscription = ai_client.data_mart.subscriptions.get(sub)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\nai_client.data_mart.subscriptions.list()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Score the model so we can begin configuring OpenScale monitors."}, {"metadata": {}, "cell_type": "code", "source": "features = list(df)\npayload_set = df.values.tolist()\n\nscoring_payload = {\n    \"fields\": features[:-1],\n    \"values\": []\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import random\nimport string\n\nletters = string.digits\n\nfor _ in range(0, 201):\n    value_to_score = random.choice(payload_set)\n    scoring_payload['values'].append(value_to_score[:-1])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predictions = wml_client.deployments.score(scoring_endpoint, scoring_payload)\nprint(predictions['values'][0])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from time import sleep\nsleep(10)\nfrom ibm_ai_openscale.supporting_classes import *\n\nsubscription.explainability.enable()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Congratulations!\n\nYou have successfully created the mortgage default model and deployed it as a web service."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}
